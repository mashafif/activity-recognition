---
title: "Capstone Project: Human Activitiy Recognition"
author: "Mashlahul Afif"
output: 
  html_document:
   toc: true
   toc_float: true
   code_folding: hide
---


##Introduction

###Background
This project is the capstone project for Introduction to Data Science's Course from Springboard

###Objectives
The main objective of this project is to explore, visualize, and finally to create machine learning model that is capable to decently classify smartphone users activity based on the smartphones sensors reading data (Accelerometer & Gyroscope).

Human activitiy recognition algorithm iscan be immensely useful in several applications:

* Development of activity based smartphone apps : excercise or workout assistance apps, augmented reality game, etc
* Healthcare applications, for automatic and intelligent daily activity monitoring for elderly people, medical diagnosis, also rehabilitation and physical therapy

![](smartphone-HAPT.PNG)

###About the Dataset
The database used in this project was collected from the accelerometers and gyroscope from the Samsung Galaxy S Smartphone and was obtained from the UCI Machine Learning Repository below:

[Human Activitiy Recognition UCI](https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip)  

From the readme of this dataset, it is mentioned that the experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz were captured. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data. 

The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). This means that 1 row of each dataset represents 1.28 sec of measurement.

The most important files from the database that will be used for this project are as the following:

* "activity_labels.txt" - this file was used as reference to label activity numbers' column included in y_train.txt and y_test.txt to their corresponding activity name (STANDING, SITTING, LAYING, WALKING, WALKING DOWNSTAIRS, or WALKING UPSTAIRS)

* "features_info.txt" - This file contains details of about the variables used on the feature vector mentioned in features.txt.

* "features.txt" - This file lists the variable names of the 561 variables. Vectors in this files later will be used to name all columns included in x_test.txt, and x_train.txt.

* "subject_test/train.txt" - This file contains the data for all participants who performed the experiments. 

* "X_test/train.txt" - This file contains data for all engineered data (not the raw data) from smartphone sensors reading. It has all the feature from "features.txt" (561 variables in total) for each participant performing each activity.

* "y_test/train.txt" -This dataset gave assigned number (between 1 and 6) of the activity from which each row of data in the "X-test/train.txt" was derived.

* Inertial Signals" folder that contains the preprocessed data of the actual sensors reading. Inertial signals consist of the following:

  + Gravitational acceleration data files for x, y and z axes: total_acc_x_train.txt, total_acc_y_train.txt, total_acc_z_train.txt.
  
  + Body acceleration data files for x, y and z axes: 
body_acc_x_train.txt, body_acc_y_train.txt, body_acc_z_train.txt.

  + Body gyroscope data files for x, y and z axes: 
body_gyro_x_train.txt,  body_gyro_y_train.txt, body_gyro_z_train.txt.

## Methodologies
To achieve the objectives the following steps, I will perform the following steps

1. Perform data wrangling using dplyr to combine, and tidy up the datasets

2. Perform data exploratory using ggplot2 to get better understanding of the data.

3. Creating the classification model using machine learning algorithm that is capable to peform multiclass classification.(e.g: random forest)

4. Evaluate the models above

## Output
Output for my final projects will be as follow:

1. Full report in form of html format created using rmarkdown

2. Power Point Presentation
